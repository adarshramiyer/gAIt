{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy.signal import savgol_filter\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def series_append(series, list, keys):\n",
    "    for i in range(64):\n",
    "        series[keys[i]].append(float(list[i]))\n",
    "    return series\n",
    "\n",
    "def load_series(filename):\n",
    "    with open(filename, 'r') as csv_in:\n",
    "        csv_file = list(csv.reader(csv_in))\n",
    "        series = {}\n",
    "        keys = csv_file[0]\n",
    "        for key in keys: series[key] = []\n",
    "        for i in range(2, len(csv_file), 2):\n",
    "            series = series_append(series, csv_file[i], keys)\n",
    "        return [series, int((len(csv_file) - 2) / 2)]\n",
    "\n",
    "def xyz_centroids(series, i):\n",
    "    x_sum = 0.0\n",
    "    y_sum = 0.0\n",
    "    z_sum = 0.0\n",
    "    for key in series:\n",
    "        if (key[-1] == 'x'):\n",
    "            x_sum += series[key][i]\n",
    "        elif (key[-1] == 'y'):\n",
    "            y_sum += series[key][i]\n",
    "        elif (key[-1] == 'z'):\n",
    "            z_sum += series[key][i]\n",
    "    x_sum /= 16.0\n",
    "    y_sum /= 16.0\n",
    "    z_sum /= 16.0\n",
    "    return [x_sum, y_sum, z_sum]\n",
    "\n",
    "def moving_average(input_list, step_size):\n",
    "    final_list = []\n",
    "    for i in range(int((step_size - 1) / 2)):\n",
    "        final_list.append(None)\n",
    "    interval_start = 0\n",
    "    interval_end = int(step_size - 1)\n",
    "    while (interval_end < len(input_list)):\n",
    "        final_list.append(int(float(sum(input_list[interval_start : interval_end + 1])) / float(step_size)))\n",
    "        interval_start += 1\n",
    "        interval_end += 1\n",
    "    for i in range(int((step_size - 1) / 2)):\n",
    "        final_list.append(None)\n",
    "    return final_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '..\\\\time_series\\\\raw\\\\'\n",
    "in_files = os.listdir(filepath)\n",
    "\n",
    "for file in in_files:\n",
    "    filename = filepath + file\n",
    "    series, num_frames = load_series(filename)\n",
    "    for key in series:\n",
    "        if (key[-1] != 'v'):\n",
    "            series[key] = savgol_filter(series[key], window_length=9, polyorder=3)\n",
    "    \n",
    "    writer = csv.writer(open('..\\\\time_series\\\\smoothed\\\\' + file, 'w'))\n",
    "    writer.writerow(series.keys())\n",
    "    writer.writerows(zip(*series.values()))\n",
    "\n",
    "    print(file)\n",
    "\n",
    "# print(sr_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filepath = '..\\\\time_series\\\\smoothed\\\\'\n",
    "in_files = os.listdir(filepath)\n",
    "\n",
    "for csv_file in in_files:\n",
    "    filename = filepath + csv_file\n",
    "    series, num_frames = load_series(filename)\n",
    "    print(csv_file)\n",
    "    # print(num_frames)\n",
    "    # print(series)\n",
    "\n",
    "    with open('..\\\\time_series\\\\translationally_normalized\\\\' + csv_file, 'w') as csv_out:\n",
    "        for frame in range(num_frames):\n",
    "            x_cent, y_cent, z_cent = xyz_centroids(series, frame)\n",
    "            for key in series:\n",
    "                # x_list.append\n",
    "                if (key[-1] == 'x'):\n",
    "                    series[key][frame] -= x_cent\n",
    "                elif (key[-1] == 'y'):\n",
    "                    series[key][frame] -= y_cent\n",
    "                elif (key[-1] == 'z'):\n",
    "                    series[key][frame] -= z_cent\n",
    "\n",
    "        writer = csv.writer(csv_out)\n",
    "        writer.writerow(series.keys())\n",
    "        writer.writerows(zip(*series.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# visualization\n",
    "series, num_frames = load_series('..\\\\time_series\\\\smoothed\\\\SR-O0-F4-B0-S2-L4-L-0004.csv')\n",
    "print(series['left_heel_y'])\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, figsize=(25, 10))\n",
    "\n",
    "ax1.plot(np.arange(0, num_frames), series['left_heel_y'], color='gray', label='Raw Pose Data')\n",
    "ax2.plot(np.arange(0, num_frames), series['left_heel_y'], color='gray', label='Raw Pose Data')\n",
    "ax1.plot(np.arange(0, num_frames), moving_average(series['left_heel_y'], 5), color='green', label='Moving Average')\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.plot(np.arange(0, num_frames), savgol_filter(series['left_heel_y'], window_length=9, polyorder=3), color='blue', label='Savitzky-Golay')\n",
    "ax2.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DO NOT USE\n",
    "\n",
    "l = series['left_heel_y']\n",
    "l = savgol_filter(l, window_length=9, polyorder=3)\n",
    "l = np.array(l)\n",
    "l -= l.mean()\n",
    "# print(l)\n",
    "l = l[6:]\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, figsize=(25, 15), sharex=False, sharey=False)\n",
    "ax1.plot(np.arange(0, len(l)), l, color='orange', label='Smoothed Data')\n",
    "\n",
    "t = np.arange(0, len(l))[1:]\n",
    "\n",
    "fourier_transform = np.fft.fft(l)\n",
    "\n",
    "fourier_transform = fourier_transform[1:]\n",
    "\n",
    "ax2.plot(t, abs(fourier_transform), color='blue', label='Fourier Transform')\n",
    "ax2.legend(), ax1.legend()\n",
    "print(abs(fourier_transform))\n",
    "\n",
    "imax=np.argmax(np.absolute(fourier_transform))\n",
    "print('VALUE AT IMAX: ' + str(fourier_transform[imax]))\n",
    "mask=np.zeros_like(fourier_transform)\n",
    "mask[imax]=1\n",
    "fourier_transform *= mask\n",
    "fdata=np.fft.ifft(fourier_transform)\n",
    "print(np.arctan2(fourier_transform[imax].imag, fourier_transform[imax].real))\n",
    "\n",
    "\n",
    "ax3.plot(t, fdata, label='Fourier Frequency')\n",
    "ax3.plot(np.arange(0,len(l)), l, color='orange', label='Smoothed Data')\n",
    "ax3.legend(loc='upper right')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# print(x_list)\n",
    "# print(y_list)\n",
    "\n",
    "\n",
    "# print(series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration of scaling features\n",
    "\n",
    "normalized_dir = '..\\\\time_series\\\\translationally_normalized\\\\'\n",
    "normalized_files = os.listdir(normalized_dir)\n",
    "\n",
    "fig, ax = plt.subplots(3, figsize=(20, 15))\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for file in normalized_files:\n",
    "    filename = normalized_dir + file\n",
    "    series, num_frames = load_series(filename)\n",
    "    shoulder_x = 'left_shoulder_x'\n",
    "    shoulder_y = 'left_shoulder_y'\n",
    "    hip_x = 'left_hip_x'\n",
    "    hip_y = 'left_hip_y'\n",
    "    knee_x = 'left_knee_x'\n",
    "    knee_y = 'left_knee_y'\n",
    "    if (file[18] == 'R'):\n",
    "        shoulder_x = 'right_shoulder_x'\n",
    "        shoulder_y = 'right_shoulder_y'\n",
    "        hip_x = 'right_hip_x'\n",
    "        hip_y = 'right_hip_y'\n",
    "        knee_x = 'right_knee_x'\n",
    "        knee_y = 'right_knee_y'\n",
    "    torso_lengths = []\n",
    "    femur_lengths = []\n",
    "    ranges = []\n",
    "    for i in range(num_frames):\n",
    "        shoulder = [series[shoulder_x][i], series[shoulder_y][i]]\n",
    "        hip = [series[hip_x][i], series[hip_y][i]]\n",
    "        knee = [series[knee_x][i], series[knee_y][i]]\n",
    "        torso_lengths.append(math.dist(shoulder, hip))\n",
    "        femur_lengths.append(math.dist(knee, hip))\n",
    "\n",
    "        y_coords = []\n",
    "\n",
    "        for key in series:\n",
    "            if (key[-1] == 'y'):\n",
    "                y_coords.append(series[key][i])\n",
    "\n",
    "        ranges.append(max(y_coords) - min(y_coords))\n",
    "\n",
    "    if (random.randint(0, 10) < 9):\n",
    "        continue\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "\n",
    "    ax[0].plot(np.arange(0, num_frames), torso_lengths)\n",
    "    ax[1].plot(np.arange(0, num_frames), femur_lengths)\n",
    "    ax[2].plot(np.arange(0, num_frames), ranges)\n",
    "    ax[0].set_title('Torso Lengths over time')\n",
    "    ax[1].set_title('Femur Lengths over time')\n",
    "    ax[2].set_title('Full-Body Range over time')\n",
    "\n",
    "    for a in ax:\n",
    "        a.set_xlabel('Frames')\n",
    "        a.set_ylabel('Pixels')\n",
    "\n",
    "fig.tight_layout(pad=2.0)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in normalized_files:\n",
    "    filename = normalized_dir + file\n",
    "    series, num_frames = load_series(filename)\n",
    "\n",
    "    shoulder_x = 'left_shoulder_x'\n",
    "    shoulder_y = 'left_shoulder_y'\n",
    "    hip_x = 'left_hip_x'\n",
    "    hip_y = 'left_hip_y'\n",
    "    if (file[18] == 'R'):\n",
    "        shoulder_x = 'right_shoulder_x'\n",
    "        shoulder_y = 'right_shoulder_y'\n",
    "        hip_x = 'right_hip_x'\n",
    "        hip_y = 'right_hip_y'\n",
    "\n",
    "    for i in range(num_frames): # for each frame\n",
    "        shoulder = [series[shoulder_x][i], series[shoulder_y][i]]\n",
    "        hip = [series[hip_x][i], series[hip_y][i]]\n",
    "        torso_length = math.dist(shoulder, hip)\n",
    "        for key in series:\n",
    "            if (key[-1] == 'x' or key[-1] == 'y'):\n",
    "                series[key][i] *= 1000\n",
    "                series[key][i] /= torso_length\n",
    "                \n",
    "    with open('..\\\\time_series\\\\scale_normalized\\\\' + file, 'w') as csv_out:\n",
    "        writer = csv.writer(csv_out)\n",
    "        writer.writerow(series.keys())\n",
    "        writer.writerows(zip(*series.values()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_normalized_dir = '..\\\\time_series\\\\scale_normalized\\\\'\n",
    "scale_normalized_files = os.listdir(scale_normalized_dir)\n",
    "\n",
    "x_aggregate = []\n",
    "y_aggregate = []\n",
    "\n",
    "for file in scale_normalized_files:\n",
    "    filename = scale_normalized_dir + file\n",
    "    series, num_frames = load_series(filename)\n",
    "    for key in series:\n",
    "        if (key[-1] == 'x'):\n",
    "            x_aggregate += series[key]\n",
    "        if (key[-1] == 'y'):\n",
    "            y_aggregate += series[key]\n",
    "\n",
    "print(len(x_aggregate))\n",
    "print(len(y_aggregate))\n",
    "\n",
    "print(min(x_aggregate))\n",
    "print(max(x_aggregate))\n",
    "\n",
    "print(min(y_aggregate))\n",
    "print(max(y_aggregate))\n",
    "\n",
    "fig, ax = plt.subplots(2, figsize=(20, 10))\n",
    "ax[0].hist(x_aggregate, bins=500)\n",
    "ax[0].set_xlim(min(x_aggregate), max(x_aggregate))\n",
    "ax[1].hist(y_aggregate, bins=500)\n",
    "ax[1].set_xlim(min(y_aggregate), max(y_aggregate))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59acfcc823b36a638b37cb1c7843aa46684cb4b3e7f7aef341e5384d13f48e0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
