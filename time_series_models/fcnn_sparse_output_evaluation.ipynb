{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def series_append(series, list, keys):\n",
    "    for i in range(64):\n",
    "        series[keys[i]].append(float(list[i]))\n",
    "    return series\n",
    "\n",
    "def load_series(filename):\n",
    "    with open(filename, 'r') as csv_in:\n",
    "        csv_file = list(csv.reader(csv_in))\n",
    "        series = {}\n",
    "        keys = csv_file[0]\n",
    "        for key in keys: series[key] = []\n",
    "        for i in range(2, len(csv_file), 2):\n",
    "            series = series_append(series, csv_file[i], keys)\n",
    "        return [series, int((len(csv_file) - 2) / 2)]\n",
    "\n",
    "def unroll(series):\n",
    "    l = []\n",
    "    for key in series:\n",
    "        if (key[-1] == 'v' or key[-1] == 'z'): continue\n",
    "        l += (series[key])\n",
    "    return l\n",
    "\n",
    "def sparse_output(filename):\n",
    "    o_index = int(filename[4])\n",
    "    f_index = int(filename[7])\n",
    "    b_index = int(filename[10])\n",
    "    s_index = int(filename[13])\n",
    "    l_index = int(filename[16])\n",
    "    output = [0.0] * 50\n",
    "    output[o_index] = 1\n",
    "    output[f_index + 10] = 1.0\n",
    "    output[b_index + 20] = 1.0\n",
    "    output[s_index + 30] = 1.0\n",
    "    output[l_index + 40] = 1.0\n",
    "    return output\n",
    "\n",
    "# TODO define sparse error functions\n",
    "\n",
    "def sparseE0(predictions, truths):\n",
    "    # returns vector of length 5 with E0 for one type of data processing\n",
    "    o_num_correct = 0\n",
    "    f_num_correct = 0\n",
    "    b_num_correct = 0\n",
    "    s_num_correct = 0\n",
    "    l_num_correct = 0\n",
    "    n = len(predictions)\n",
    "    for i in range(len(predictions)):\n",
    "        pred = predictions[i]\n",
    "\n",
    "        truth = [int(j) for j in truths[i]]\n",
    "\n",
    "        if (pred[truth[0]] > 0.5): # if overstride correct\n",
    "            o_num_correct+=1\n",
    "        if (pred[truth[1] + 10] > 0.5): # if forward lean correct\n",
    "            f_num_correct+=1\n",
    "        if (pred[truth[2] + 20] > 0.5): # if backward lean correct\n",
    "            b_num_correct+=1 \n",
    "        if (pred[truth[3] + 30] > 0.5): # if sweeping correct\n",
    "            s_num_correct+=1\n",
    "        if (pred[truth[4] + 40] > 0.5): # if low arms correct\n",
    "            l_num_correct+=1\n",
    "    return [float(o_num_correct) / n, float(f_num_correct) / n, float(b_num_correct) / n, float(s_num_correct) / n, float(l_num_correct) / n]\n",
    "\n",
    "\n",
    "\n",
    "def sparseE1(predictions, truths):\n",
    "    # returns vector of length 5 with E0 for one type of data processing\n",
    "    o_num_correct = 0\n",
    "    f_num_correct = 0\n",
    "    b_num_correct = 0\n",
    "    s_num_correct = 0\n",
    "    l_num_correct = 0\n",
    "    n = len(predictions)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        pred = predictions[i]\n",
    "\n",
    "        truth = [int(j) for j in truths[i]]\n",
    "\n",
    "        o_space = np.arange(max(truth[0] - 1, 0), min(truth[0] + 2, 9))\n",
    "        f_space = np.arange(max(truth[1] + 10 - 1, 10), min(truth[1] + 10 + 2, 19))\n",
    "        b_space = np.arange(max(truth[2] + 20 - 1, 20), min(truth[2] + 20 + 2, 29))\n",
    "        s_space = np.arange(max(truth[3] + 30 - 1, 30), min(truth[3] + 30 + 2, 39))\n",
    "        l_space = np.arange(max(truth[4] + 40 - 1, 40), min(truth[4] + 40 + 2, 49))\n",
    "\n",
    "        for truth_index in o_space:\n",
    "            if (pred[truth_index] > 0.5): # if overstride correct\n",
    "                o_num_correct+=1\n",
    "                break\n",
    "\n",
    "        for truth_index in f_space:\n",
    "            if (pred[truth_index] > 0.5): # if forward lean correct\n",
    "                f_num_correct+=1\n",
    "                break\n",
    "        \n",
    "        for truth_index in b_space:\n",
    "            if (pred[truth_index] > 0.5): # if backward lean correct\n",
    "                b_num_correct+=1\n",
    "                break\n",
    "\n",
    "        for truth_index in s_space:\n",
    "            if (pred[truth_index] > 0.5): # if sweeping correct\n",
    "                s_num_correct+=1\n",
    "                break\n",
    "\n",
    "        for truth_index in l_space:\n",
    "            if (pred[truth_index] > 0.5): # if low arms correct\n",
    "                l_num_correct+=1\n",
    "                break\n",
    "        \n",
    "    return [float(o_num_correct) / n, float(f_num_correct) / n, float(b_num_correct) / n, float(s_num_correct) / n, float(l_num_correct) / n]\n",
    "\n",
    "\n",
    "\n",
    "def sparseE2(predictions, truths):\n",
    "    # returns vector of length 5 with E0 for one type of data processing\n",
    "    o_num_correct = 0\n",
    "    f_num_correct = 0\n",
    "    b_num_correct = 0\n",
    "    s_num_correct = 0\n",
    "    l_num_correct = 0\n",
    "    n = len(predictions)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        pred = predictions[i]\n",
    "\n",
    "        truth = [int(j) for j in truths[i]]\n",
    "\n",
    "        o_space = np.arange(max(truth[0] - 2, 0), min(truth[0] + 3, 9))\n",
    "        f_space = np.arange(max(truth[1] + 10 - 2, 10), min(truth[1] + 10 + 3, 19))\n",
    "        b_space = np.arange(max(truth[2] + 20 - 2, 20), min(truth[2] + 20 + 3, 29))\n",
    "        s_space = np.arange(max(truth[3] + 30 - 2, 30), min(truth[3] + 30 + 3, 39))\n",
    "        l_space = np.arange(max(truth[4] + 40 - 2, 40), min(truth[4] + 40 + 3, 49))\n",
    "\n",
    "        for truth_index in o_space:\n",
    "            if (pred[truth_index] > 0.5): # if overstride correct\n",
    "                o_num_correct+=1\n",
    "                break\n",
    "\n",
    "        for truth_index in f_space:\n",
    "            if (pred[truth_index] > 0.5): # if forward lean correct\n",
    "                f_num_correct+=1\n",
    "                break\n",
    "        \n",
    "        for truth_index in b_space:\n",
    "            if (pred[truth_index] > 0.5): # if backward lean correct\n",
    "                b_num_correct+=1\n",
    "                break\n",
    "\n",
    "        for truth_index in s_space:\n",
    "            if (pred[truth_index] > 0.5): # if sweeping correct\n",
    "                s_num_correct+=1\n",
    "                break\n",
    "\n",
    "        for truth_index in l_space:\n",
    "            if (pred[truth_index] > 0.5): # if low arms correct\n",
    "                l_num_correct+=1\n",
    "                break\n",
    "        \n",
    "    return [float(o_num_correct) / n, float(f_num_correct) / n, float(b_num_correct) / n, float(s_num_correct) / n, float(l_num_correct) / n]\n",
    "\n",
    "\n",
    "\n",
    "def sparseE3(predictions, truths):\n",
    "    # returns vector of length 5 with E0 for one type of data processing\n",
    "    o_num_correct = 0\n",
    "    f_num_correct = 0\n",
    "    b_num_correct = 0\n",
    "    s_num_correct = 0\n",
    "    l_num_correct = 0\n",
    "    n = len(predictions)\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        pred = predictions[i]\n",
    "        \n",
    "        truth = [int(j) for j in truths[i]]\n",
    "\n",
    "        o_space = np.arange(max(truth[0] - 3, 0), min(truth[0] + 4, 9))\n",
    "        f_space = np.arange(max(truth[1] + 10 - 3, 10), min(truth[1] + 10 + 4, 19))\n",
    "        b_space = np.arange(max(truth[2] + 20 - 3, 20), min(truth[2] + 20 + 4, 29))\n",
    "        s_space = np.arange(max(truth[3] + 30 - 3, 30), min(truth[3] + 30 + 4, 39))\n",
    "        l_space = np.arange(max(truth[4] + 40 - 3, 40), min(truth[4] + 40 + 4, 49))\n",
    "\n",
    "        for truth_index in o_space:\n",
    "            if (pred[truth_index] > 0.5): # if overstride correct\n",
    "                o_num_correct+=1\n",
    "                break\n",
    "\n",
    "        for truth_index in f_space:\n",
    "            if (pred[truth_index] > 0.5): # if forward lean correct\n",
    "                f_num_correct+=1\n",
    "                break\n",
    "        \n",
    "        for truth_index in b_space:\n",
    "            if (pred[truth_index] > 0.5): # if backward lean correct\n",
    "                b_num_correct+=1\n",
    "                break\n",
    "\n",
    "        for truth_index in s_space:\n",
    "            if (pred[truth_index] > 0.5): # if sweeping correct\n",
    "                s_num_correct+=1\n",
    "                break\n",
    "\n",
    "        for truth_index in l_space:\n",
    "            if (pred[truth_index] > 0.5): # if low arms correct\n",
    "                l_num_correct+=1\n",
    "                break\n",
    "        \n",
    "    return [float(o_num_correct) / n, float(f_num_correct) / n, float(b_num_correct) / n, float(s_num_correct) / n, float(l_num_correct) / n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([93, 224])\n",
      "torch.Size([93, 224])\n",
      "torch.Size([93, 224])\n",
      "torch.Size([93, 224])\n",
      "torch.Size([93, 50])\n",
      "torch.Size([93, 5])\n",
      "\n",
      "\n",
      "\n",
      "torch.Size([371, 224])\n",
      "torch.Size([371, 224])\n",
      "torch.Size([371, 224])\n",
      "torch.Size([371, 224])\n",
      "torch.Size([371, 50])\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "\n",
    "raw_X_train_list = []\n",
    "smoothed_X_train_list = []\n",
    "trans_X_train_list = []\n",
    "final_X_train_list = []\n",
    "\n",
    "y_train_list = []\n",
    "\n",
    "raw_X_test_list = []\n",
    "smoothed_X_test_list = []\n",
    "trans_X_test_list = []\n",
    "final_X_test_list = []\n",
    "\n",
    "y_test_list = []\n",
    "y_sparse_test_list = []\n",
    "\n",
    "with open(\"..\\\\test_examples.txt\") as t:\n",
    "    test_examples = t.readlines()\n",
    "\n",
    "for example in test_examples:\n",
    "    raw_series, num_frames = load_series(\"..\\\\time_series\\\\Time_normalized_stages\\\\1_unprocessed\\\\\" + example[:-1])\n",
    "    smoothed_series, num_frames = load_series(\"..\\\\time_series\\\\Time_normalized_stages\\\\2_smoothed\\\\\" + example[:-1])\n",
    "    trans_series, num_frames = load_series(\"..\\\\time_series\\\\Time_normalized_stages\\\\3_translation\\\\\" + example[:-1])\n",
    "    final_series, num_frames = load_series(\"..\\\\time_series\\\\Time_normalized_stages\\\\4_final\\\\\" + example[:-1])\n",
    "\n",
    "    raw_X_test_list.append(unroll(raw_series))\n",
    "    smoothed_X_test_list.append(unroll(smoothed_series))\n",
    "    trans_X_test_list.append(unroll(trans_series))\n",
    "    final_X_test_list.append(unroll(final_series))\n",
    "    \n",
    "    y_test_list.append([int(example[4]), int(example[7]), int(example[10]), int(example[13]), int(example[16])])\n",
    "    y_sparse_test_list.append(sparse_output(example))\n",
    "\n",
    "raw_X_test = torch.tensor(raw_X_test_list)\n",
    "smoothed_X_test = torch.tensor(smoothed_X_test_list)\n",
    "trans_X_test = torch.tensor(trans_X_test_list)\n",
    "final_X_test = torch.tensor(final_X_test_list)\n",
    "\n",
    "y_sparse_test = torch.tensor(y_sparse_test_list)\n",
    "y_test = torch.tensor(y_test_list)\n",
    "\n",
    "print(raw_X_test.size())\n",
    "print(smoothed_X_test.size())\n",
    "print(trans_X_test.size())\n",
    "print(final_X_test.size())\n",
    "print(y_sparse_test.size())\n",
    "print(y_test.size())\n",
    "print('\\n\\n')\n",
    "\n",
    "with open(\"..\\\\training_examples.txt\") as t:\n",
    "    training_examples = t.readlines()\n",
    "\n",
    "for example in training_examples:\n",
    "    raw_series, num_frames = load_series(\"..\\\\time_series\\\\Time_normalized_stages\\\\1_unprocessed\\\\\" + example[:-1])\n",
    "    smoothed_series, num_frames = load_series(\"..\\\\time_series\\\\Time_normalized_stages\\\\2_smoothed\\\\\" + example[:-1])\n",
    "    trans_series, num_frames = load_series(\"..\\\\time_series\\\\Time_normalized_stages\\\\3_translation\\\\\" + example[:-1])\n",
    "    final_series, num_frames = load_series(\"..\\\\time_series\\\\Time_normalized_stages\\\\4_final\\\\\" + example[:-1])\n",
    "    y_example = sparse_output(example)\n",
    "\n",
    "    raw_X_train_list.append(unroll(raw_series))\n",
    "    smoothed_X_train_list.append(unroll(smoothed_series))\n",
    "    trans_X_train_list.append(unroll(trans_series))\n",
    "    final_X_train_list.append(unroll(final_series))\n",
    "    \n",
    "    y_train_list.append(y_example)\n",
    "\n",
    "raw_X_train = torch.tensor(raw_X_train_list)\n",
    "smoothed_X_train = torch.tensor(smoothed_X_train_list)\n",
    "trans_X_train = torch.tensor(trans_X_train_list)\n",
    "final_X_train = torch.tensor(final_X_train_list)\n",
    "\n",
    "y_train = torch.tensor(y_train_list)\n",
    "\n",
    "print(raw_X_train.size())\n",
    "print(smoothed_X_train.size())\n",
    "print(trans_X_train.size())\n",
    "print(final_X_train.size())\n",
    "print(y_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model, parameters, and weight initialization\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "input_size = 224\n",
    "hidden_layer_size_1 = 450\n",
    "hidden_layer_size_2 = 420\n",
    "hidden_layer_size_3 = 350\n",
    "hidden_layer_size_4 = 270\n",
    "hidden_layer_size_5 = 150\n",
    "hidden_layer_size_6 = 100\n",
    "output_size = 50\n",
    "batch_size = 371\n",
    "learning_rate = 0.001\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_layer_size_1),\n",
    "                        nn.Mish(),\n",
    "                        nn.Linear(hidden_layer_size_1, hidden_layer_size_2),\n",
    "                        nn.Mish(),\n",
    "                        nn.Linear(hidden_layer_size_2, hidden_layer_size_3),\n",
    "                        nn.Mish(),\n",
    "                        nn.Linear(hidden_layer_size_3, hidden_layer_size_4),\n",
    "                        nn.Mish(),\n",
    "                        nn.Linear(hidden_layer_size_4, hidden_layer_size_5),\n",
    "                        nn.Mish(),\n",
    "                        nn.Linear(hidden_layer_size_5, hidden_layer_size_6),\n",
    "                        nn.Mish(),\n",
    "                        nn.Linear(hidden_layer_size_6, output_size),\n",
    "                        nn.Sigmoid())\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "num_epochs = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07259393483400345\n",
      "RAW E0: [0.10752688172043011, 0.4838709677419355, 0.3010752688172043, 0.06451612903225806, 0.3333333333333333]\n",
      "RAW E1: [0.1935483870967742, 0.5591397849462365, 0.3763440860215054, 0.15053763440860216, 0.41935483870967744]\n",
      "RAW E2: [0.20430107526881722, 0.5806451612903226, 0.43010752688172044, 0.1935483870967742, 0.4946236559139785]\n",
      "RAW E3: [0.21505376344086022, 0.6236559139784946, 0.4838709677419355, 0.23655913978494625, 0.5591397849462365]\n"
     ]
    }
   ],
   "source": [
    "# training and evaluating raw series\n",
    "\n",
    "min_loss = 1.0\n",
    "\n",
    "training_cycles = 1\n",
    "\n",
    "raw_E0 = []\n",
    "raw_E1 = []\n",
    "raw_E2 = []\n",
    "raw_E3 = []\n",
    "\n",
    "for i in range(training_cycles):\n",
    "    model.apply(init_weights)\n",
    "    test_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        pred_y = model(raw_X_train)\n",
    "        loss = loss_function(pred_y, y_train)\n",
    "\n",
    "        test_y = model(raw_X_test)\n",
    "        test_loss = loss_function(test_y, y_sparse_test)\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    if (min(test_losses) < min_loss):\n",
    "        min_loss = min(test_losses)\n",
    "        test_y = model(raw_X_test)\n",
    "\n",
    "        raw_E0.clear()\n",
    "        raw_E1.clear()\n",
    "        raw_E2.clear()\n",
    "        raw_E3.clear()\n",
    "\n",
    "        raw_E0 = sparseE0(test_y, y_test.tolist())\n",
    "        raw_E1 = sparseE1(test_y, y_test.tolist())\n",
    "        raw_E2 = sparseE2(test_y, y_test.tolist())\n",
    "        raw_E3 = sparseE3(test_y, y_test.tolist())\n",
    "\n",
    "print('MSE: ' + str(min_loss))\n",
    "print('RAW E0: ' + str(raw_E0))\n",
    "print('RAW E1: ' + str(raw_E1))\n",
    "print('RAW E2: ' + str(raw_E2))\n",
    "print('RAW E3: ' + str(raw_E3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07141277939081192\n",
      "SMOOTHED E0: [0.11827956989247312, 0.5591397849462365, 0.24731182795698925, 0.010752688172043012, 0.3870967741935484]\n",
      "SMOOTHED E1: [0.23655913978494625, 0.6129032258064516, 0.2903225806451613, 0.010752688172043012, 0.4946236559139785]\n",
      "SMOOTHED E2: [0.27956989247311825, 0.6236559139784946, 0.34408602150537637, 0.010752688172043012, 0.5483870967741935]\n",
      "SMOOTHED E3: [0.27956989247311825, 0.6666666666666666, 0.3548387096774194, 0.010752688172043012, 0.6129032258064516]\n"
     ]
    }
   ],
   "source": [
    "# training and evaluating smoothed series\n",
    "\n",
    "min_loss = 1.0\n",
    "\n",
    "training_cycles = 1\n",
    "\n",
    "smooth_E0 = []\n",
    "smooth_E1 = []\n",
    "smooth_E2 = []\n",
    "smooth_E3 = []\n",
    "\n",
    "for i in range(training_cycles):\n",
    "    model.apply(init_weights)\n",
    "    test_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        pred_y = model(smoothed_X_train)\n",
    "        loss = loss_function(pred_y, y_train)\n",
    "\n",
    "        test_y = model(smoothed_X_test)\n",
    "        test_loss = loss_function(test_y, y_sparse_test)\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    if (min(test_losses) < min_loss):\n",
    "        min_loss = min(test_losses)\n",
    "        test_y = model(smoothed_X_test)\n",
    "\n",
    "        smooth_E0.clear()\n",
    "        smooth_E1.clear()\n",
    "        smooth_E2.clear()\n",
    "        smooth_E3.clear()\n",
    "\n",
    "        smooth_E0 = sparseE0(test_y, y_test.tolist())\n",
    "        smooth_E1 = sparseE1(test_y, y_test.tolist())\n",
    "        smooth_E2 = sparseE2(test_y, y_test.tolist())\n",
    "        smooth_E3 = sparseE3(test_y, y_test.tolist())\n",
    "\n",
    "print('MSE: ' + str(min_loss))\n",
    "print('SMOOTHED E0: ' + str(smooth_E0))\n",
    "print('SMOOTHED E1: ' + str(smooth_E1))\n",
    "print('SMOOTHED E2: ' + str(smooth_E2))\n",
    "print('SMOOTHED E3: ' + str(smooth_E3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07472506165504456\n",
      "TRANS E0: [0.0, 0.6989247311827957, 0.44086021505376344, 0.0, 0.0]\n",
      "TRANS E1: [0.0, 0.7634408602150538, 0.5268817204301075, 0.0, 0.0]\n",
      "TRANS E2: [0.0, 0.7741935483870968, 0.6236559139784946, 0.0, 0.0]\n",
      "TRANS E3: [0.0, 0.8387096774193549, 0.6881720430107527, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# training and evaluating translationally normalized series\n",
    "\n",
    "min_loss = 1.0\n",
    "\n",
    "training_cycles = 1\n",
    "\n",
    "trans_E0 = []\n",
    "trans_E1 = []\n",
    "trans_E2 = []\n",
    "trans_E3 = []\n",
    "\n",
    "for i in range(training_cycles):\n",
    "    model.apply(init_weights)\n",
    "    test_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        pred_y = model(trans_X_train)\n",
    "        loss = loss_function(pred_y, y_train)\n",
    "\n",
    "        test_y = model(trans_X_test)\n",
    "        test_loss = loss_function(test_y, y_sparse_test)\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    if (min(test_losses) < min_loss):\n",
    "        min_loss = min(test_losses)\n",
    "        test_y = model(trans_X_test)\n",
    "\n",
    "        trans_E0.clear()\n",
    "        trans_E1.clear()\n",
    "        trans_E2.clear()\n",
    "        trans_E3.clear()\n",
    "\n",
    "        trans_E0 = sparseE0(test_y, y_test.tolist())\n",
    "        trans_E1 = sparseE1(test_y, y_test.tolist())\n",
    "        trans_E2 = sparseE2(test_y, y_test.tolist())\n",
    "        trans_E3 = sparseE3(test_y, y_test.tolist())\n",
    "\n",
    "print('MSE: ' + str(min_loss))\n",
    "print('TRANS E0: ' + str(trans_E0))\n",
    "print('TRANS E1: ' + str(trans_E1))\n",
    "print('TRANS E2: ' + str(trans_E2))\n",
    "print('TRANS E3: ' + str(trans_E3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06743676960468292\n",
      "FINAL E0: [0.22580645161290322, 0.6559139784946236, 0.3763440860215054, 0.1827956989247312, 0.43010752688172044]\n",
      "FINAL E1: [0.3763440860215054, 0.7526881720430108, 0.4731182795698925, 0.3333333333333333, 0.5806451612903226]\n",
      "FINAL E2: [0.44086021505376344, 0.7741935483870968, 0.4838709677419355, 0.41935483870967744, 0.6451612903225806]\n",
      "FINAL E3: [0.45161290322580644, 0.8064516129032258, 0.4946236559139785, 0.45161290322580644, 0.6666666666666666]\n"
     ]
    }
   ],
   "source": [
    "# training and evaluating final series\n",
    "\n",
    "min_loss = 1.0\n",
    "\n",
    "training_cycles = 1\n",
    "\n",
    "final_E0 = []\n",
    "final_E1 = []\n",
    "final_E2 = []\n",
    "final_E3 = []\n",
    "\n",
    "for i in range(training_cycles):\n",
    "    model.apply(init_weights)\n",
    "    test_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        pred_y = model(final_X_train)\n",
    "        loss = loss_function(pred_y, y_train)\n",
    "\n",
    "        test_y = model(final_X_test)\n",
    "        test_loss = loss_function(test_y, y_sparse_test)\n",
    "        test_losses.append(test_loss.item())\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    if (min(test_losses) < min_loss):\n",
    "        min_loss = min(test_losses)\n",
    "        test_y = model(final_X_test)\n",
    "\n",
    "        final_E0.clear()\n",
    "        final_E1.clear()\n",
    "        final_E2.clear()\n",
    "        final_E3.clear()\n",
    "\n",
    "        final_E0 = sparseE0(test_y, y_test.tolist())\n",
    "        final_E1 = sparseE1(test_y, y_test.tolist())\n",
    "        final_E2 = sparseE2(test_y, y_test.tolist())\n",
    "        final_E3 = sparseE3(test_y, y_test.tolist())\n",
    "\n",
    "print('MSE: ' + str(min_loss))\n",
    "print('FINAL E0: ' + str(final_E0))\n",
    "print('FINAL E1: ' + str(final_E1))\n",
    "print('FINAL E2: ' + str(final_E2))\n",
    "print('FINAL E3: ' + str(final_E3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59acfcc823b36a638b37cb1c7843aa46684cb4b3e7f7aef341e5384d13f48e0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
